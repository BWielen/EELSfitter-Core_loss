{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CLfitter import *\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25750b57",
   "metadata": {},
   "source": [
    "The first step to obtain a background prediction is defining the NN architecture. It was found that a 2,16,1 architecture works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4669a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EELSBackgroundNN(nn.Module):\n",
    "     def __init__(self):\n",
    "          super().__init__()\n",
    "          self.model = nn.Sequential(\n",
    "               nn.Linear( 2, 16),\n",
    "               nn.SiLU(),\n",
    "               nn.Linear(16, 1)\n",
    "          )\n",
    "     def forward(self, x):\n",
    "          return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b948a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'data/twisted-CrSBr-2deg-eels-SI_004.dm4'\n",
    "i = (520,570,670) #E_min, E_I, E_max\n",
    "n_clusters = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc935a1d",
   "metadata": {},
   "source": [
    "**DataHandler** is called to handle the data.\n",
    ".read_dm4_SI can obtain data from either dm3 and dm4 files, with core_loss_index begin the index of the core-loss data. This index can either be found by trail and error or opening GMS and checking the entry. Index runs from 0, so keep that in mind.\n",
    "\n",
    "**Pooler** is used to pool the data per energy bin. Either a gaussian or a square kernel can be used, and a radius can be defined.\n",
    "\n",
    "Due to how some EELS spectroscopes gather data, negative counts can be obtained. All entries less than 1 are therefore set to 1 (also to avoid ln(0) later on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = dm.file_reader(path)\n",
    "data_handler = DataHandler()\n",
    "data_handler.read_dm4_SI(path, core_loss_index=3, lowloss=False)\n",
    "\n",
    "pooler = Pooler(data_handler.signal, data_handler.si_size)\n",
    "signal =  pooler.pool_data(sqr_radius=2, gaussian_kernel=True)\n",
    "signal[signal<1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937e63c",
   "metadata": {},
   "source": [
    "Some pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define E_min, E_I and E_max\n",
    "range_mask = (data_handler.energy_axis > i[0]) & (data_handler.energy_axis < i[-1])  # Range for clustering shape [n_E_1]\n",
    "energy_range = data_handler.energy_axis[range_mask] # shape [n_E_1]\n",
    "signal_range = signal.copy()[range_mask,:]  # shape [n_E_1, n_y*n_x]\n",
    "pre_edge_mask = (energy_range > i[0]) & (energy_range < i[1])  # Range for pre-edge shape [n_E_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019520ac",
   "metadata": {},
   "source": [
    "**Clusterer** clusters the data in n_clusters clusters. .cholesky_decomp calculates the cholesky decomposition of the covariance matrices.\n",
    "\n",
    "**X_Builder** makes the X data for the NN training, both MC and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusterer = ClusterAnalyzer(signal_range)\n",
    "clusterer.cluster_data(n_clusters = n_clusters, pre_edge_mask=pre_edge_mask,)\n",
    "clusterer.cholesky_decomp()\n",
    "\n",
    "X_builder = X_Builder(energy_range)\n",
    "X_builder.prepare_X_mc_data(clusterer.cluster_centers, i[1])\n",
    "X_builder.prepare_X_eval_data(clusterer.total_integrated_intensity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5424c0",
   "metadata": {},
   "source": [
    "The following cell trains the NN's and saves the results. It does this in parallel, each core running 10 NN's consecutively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_background(ii, signal_range, pre_edge_mask, X_builder, clusterer, i):\n",
    "    background_trainer = BackgroundTrainer(\n",
    "        signal=signal_range,\n",
    "        pre_edge_mask=pre_edge_mask,\n",
    "        X_mc=X_builder.X_mc,\n",
    "        X_eval=X_builder.X_eval,\n",
    "        clustered_spectra_mean=clusterer.clusters_mean,\n",
    "        triangular_matices=clusterer.triangular_matices,\n",
    "        covariance_matrices=clusterer.clusters_covariance,\n",
    "        cluster_labels=clusterer.clusters\n",
    "    )\n",
    "\n",
    "    background_trainer.train_MC_replica_consecutive(\n",
    "        n_mc_replicas=5, \n",
    "        epochs=20000, \n",
    "        edge_onset=i[1],\n",
    "        replica_version='covariance',\n",
    "        model = EELSBackgroundNN(),        \n",
    "        progress = False,\n",
    "        logging = False\n",
    "    )\n",
    "    predictions = background_trainer.background\n",
    "    prediction_saver = PredictionSaver(\n",
    "        signal=signal_range,\n",
    "        energy_axis=energy_range,\n",
    "        spatial_axis_x=data_handler.spatial_axis_x,\n",
    "        spatial_axis_y=data_handler.spatial_axis_y,\n",
    "        predictions=predictions\n",
    "    )\n",
    "\n",
    "    folder_path = fr'fitruns'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    filename = f'run_{i[0]}-{i[1]}-{i[2]}v{ii}.npz'\n",
    "    path_to_save = os.path.join(folder_path, filename)\n",
    "    prediction_saver.save_predictions(path_to_save)\n",
    "    \n",
    "    # np.savez(f'bvdwiele/realresults/pred_{ii}.npz', pred = background_trainer.background)\n",
    "    \n",
    "    del background_trainer\n",
    "    # Force garbage collection\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "# Number of parallel jobs (adjust based on your CPU cores)\n",
    "n_jobs = 4\n",
    "\n",
    "Parallel(n_jobs=n_jobs)(\n",
    "    delayed(train_background)(ii, signal_range, pre_edge_mask, X_builder, clusterer, i)\n",
    "    for ii in range(0, 4) #100*10 = 1000 total replicas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51603b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "class PredictionChecker:\n",
    "    def __init__(self, path):\n",
    "        data = np.load(path)\n",
    "\n",
    "        self.predictions = data['predictions']  # shape (n_mc, n_spatial, n_E)\n",
    "        self.signal = data['signal']            # shape (n_E, n_spatial)\n",
    "        self.energy_axis = data['energy_axis']  # shape (n_E,)\n",
    "        self.y_axis = data['spatial_axis_y']\n",
    "        self.x_axis = data['spatial_axis_x']\n",
    "\n",
    "        self.edge_mean = np.mean(\n",
    "            self.signal.T[None, :, :] - self.predictions, axis=0\n",
    "        )  # shape (n_spatial, n_E)\n",
    "        self.edge_stdev = np.std(\n",
    "            self.signal.T[None, :, :] - self.predictions, axis=0\n",
    "        )\n",
    "\n",
    "        self.spatial_size = (len(self.y_axis), len(self.x_axis))\n",
    "\n",
    "    @staticmethod\n",
    "    def _two_gauss_two_arctan(x,\n",
    "                            A1, mu1, sigma1,\n",
    "                            A2, mu2, sigma2,\n",
    "                            C1, x01, w1,\n",
    "                            C2, x02, w2):\n",
    "        \"\"\"\n",
    "        Model = 2 Gaussians + 2 shifted arctan steps).\n",
    "        \"\"\"\n",
    "        g1 = A1 * np.exp(-(x - mu1) ** 2 / (2 * sigma1 ** 2))\n",
    "        g2 = A2 * np.exp(-(x - mu2) ** 2 / (2 * sigma2 ** 2))\n",
    "        ar1 = C1 * (np.arctan((x - x01) / (w1 + 1e-12)) + np.pi / 2.0)\n",
    "        ar2 = C2 * (np.arctan((x - x02) / (w2 + 1e-12)) + np.pi / 2.0)\n",
    "        return g1 + g2 + ar1 + ar2\n",
    "    \n",
    "        \n",
    "    def _fit_and_integrate_white_lines(self, spectrum, mu_guesses, fit_window=5.0, integration_window=1.5):\n",
    "        \"\"\"\n",
    "        LMfit: fit spectrum with 2 Gaussians + 2 shifted arctans.\n",
    "        Returns: area1, area2, mu1, mu2, (step1_height, step2_height)\n",
    "        \"\"\"\n",
    "        energy = self.energy_axis\n",
    "        mask_fit = (energy > min(mu_guesses) - fit_window) & (energy < max(mu_guesses) + fit_window)\n",
    "        x = energy[mask_fit]\n",
    "        y = spectrum[mask_fit]\n",
    "\n",
    "        if len(x) < 5 or np.all(y <= 0):\n",
    "            return np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan\n",
    "\n",
    "        # Initial guesses\n",
    "        A1_guess = max(y[(x > mu_guesses[0]-0.5) & (x < mu_guesses[0]+0.5)].max(), 1e-3)\n",
    "        A2_guess = max(y[(x > mu_guesses[1]-0.5) & (x < mu_guesses[1]+0.5)].max(), 1e-3)\n",
    "        C_guess = max((y[-1] - y[0]) * 0.3, 1e-3)\n",
    "\n",
    "        model = Model(self._two_gauss_two_arctan)\n",
    "        params = Parameters()\n",
    "\n",
    "        #sharpness\n",
    "        params.add(\"A1\", value=A1_guess, min=0)\n",
    "        params.add(\"A2\", value=A2_guess, min=0)\n",
    "\n",
    "        params.add(\"C1\", value=C_guess, min=1)\n",
    "        params.add(\"C2\", value=C_guess, min=1)\n",
    "       \n",
    "        #sharpness\n",
    "        params.add(\"sigma1\", value=0.7, min=0.1, max=2.0)\n",
    "        params.add(\"sigma2\", value=0.7, min=0.1, max=2.0)\n",
    "\n",
    "        params.add(\"w1\", value=0.5, min=0.01, max=2)\n",
    "\n",
    "        params.add(\"delta_w\", value=0.0, min=-0.5, max=0.5)  # allow Â±0.5 eV difference\n",
    "        params.add(\"w2\", expr=\"w1+delta_w\")\n",
    "\n",
    "        #onsets\n",
    "        params.add(\"mu1\", value=mu_guesses[0], min=mu_guesses[0]-2, max=mu_guesses[0]+2)\n",
    "        params.add(\"mu2\", value=mu_guesses[1], min=mu_guesses[1]-2, max=mu_guesses[1]+2)\n",
    "\n",
    "        params.add('deltax01', value=0, min=-1, max=1)\n",
    "        params.add(\"x01\", expr = 'mu1+deltax01')\n",
    "        params.add('deltax02', value=0, min=-1, max=1)\n",
    "        params.add(\"x02\", expr = 'mu2+deltax02')\n",
    "        \n",
    "        try:\n",
    "            result = model.fit(y, params, x=x)\n",
    "            best = result.best_values\n",
    "            fit_y = result.best_fit\n",
    "\n",
    "            mu1, mu2 = best[\"mu1\"], best[\"mu2\"]\n",
    "            C1, x01, w1 = best[\"C1\"], best[\"x01\"], best[\"w1\"]\n",
    "            C2, x02, w2 = best[\"C2\"], best[\"x02\"], best[\"w2\"]\n",
    "            A1, A2, sigma1, sigma2 = best['A1'],best['A2'], best['sigma2'], best['sigma2']\n",
    "\n",
    "            return C1, C2, A1, A2, sigma1, sigma2, mu1, mu2\n",
    "\n",
    "        except Exception:\n",
    "            print('bonk')\n",
    "            return np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan\n",
    "\n",
    "\n",
    "    def white_line_calculation_MC(self, L3_guess=577, L2_guess=586, integration_window=1.5, fit_window=5):\n",
    "        '''\n",
    "        Code for obtaining the normalized white line intensity values for each entry in the MC ensemble\n",
    "\n",
    "        '''\n",
    "        J = self.predictions.shape[0]\n",
    "        I = self.edge_mean.shape[0]\n",
    "\n",
    "        C1  = np.full((J,I), np.nan)\n",
    "        C2  = np.full((J,I), np.nan)\n",
    "        A1  = np.full((J,I), np.nan)\n",
    "        A2 = np.full((J,I), np.nan)\n",
    "        sigma1 = np.full((J,I), np.nan)\n",
    "        sigma2 = np.full((J,I), np.nan)\n",
    "        mu1 = np.full((J,I), np.nan)\n",
    "        mu2 = np.full((J,I), np.nan)\n",
    "\n",
    "        replicas = self.signal.T[None, :, :] - self.predictions\n",
    "\n",
    "        for j in range(J):\n",
    "            print(f'replica {j+1}/{J}')\n",
    "            for i in range(I):\n",
    "                spectrum = replicas[j, i, :]\n",
    "                C1[j, i], C2[j, i], A1[j, i], A2[j, i], sigma1[j, i], sigma2[j, i], mu1[j, i], mu2[j, i] = self._fit_and_integrate_white_lines(\n",
    "                    spectrum, (L3_guess, L2_guess),\n",
    "                    fit_window=fit_window, integration_window=integration_window\n",
    "                )\n",
    "\n",
    "        return C1, C2, A1, A2, sigma1, sigma2, mu1, mu2\n",
    "    \n",
    "    def plot_fit_diagnostic(self, spectrum, mu_guesses=(577, 586), fit_window=5):\n",
    "        \"\"\"\n",
    "        Plot a spectrum with its fit and individual components. Does nothing other than plot, just for the figure in the paper\n",
    "        \"\"\"\n",
    "        # mask window\n",
    "        mask_fit = (self.energy_axis > min(mu_guesses) - fit_window) & \\\n",
    "                   (self.energy_axis < max(mu_guesses) + fit_window)\n",
    "        x = self.energy_axis[mask_fit]\n",
    "        y = spectrum[mask_fit]\n",
    "\n",
    "        # Run the fit\n",
    "        fit_result = self._fit_single_spectrum_with_initial_guess(\n",
    "            spectrum, self.energy_axis, mu_guesses, fit_window=fit_window\n",
    "        )\n",
    "\n",
    "        if fit_result is None or not fit_result.success:\n",
    "            print(\"Fit failed.\")\n",
    "            return\n",
    "\n",
    "        best = fit_result.best_values\n",
    "\n",
    "        # Reconstruct components\n",
    "        g1 = best[\"A1\"] * np.exp(-(x - best[\"mu1\"]) ** 2 / (2 * best[\"sigma1\"] ** 2))\n",
    "        g2 = best[\"A2\"] * np.exp(-(x - best[\"mu2\"]) ** 2 / (2 * best[\"sigma2\"] ** 2))\n",
    "        ar1 = best[\"C1\"] * (np.arctan((x - best[\"x01\"]) / (best[\"w1\"] + 1e-12)) + np.pi/2)\n",
    "        ar2 = best[\"C2\"] * (np.arctan((x - best[\"x02\"]) / (best[\"w2\"] + 1e-12)) + np.pi/2)\n",
    "        total_fit = g1 + g2 + ar1 + ar2\n",
    "\n",
    "        # Plot        \n",
    "        fig = plt.figure(figsize = (8,8))\n",
    "\n",
    "        ax = fig.add_axes([0.2,0.2,0.7,0.7])        \n",
    "        \n",
    "        ax.plot(x, y, \"-\", label=\"Subtracted EELS Data\", lw=2, color = 'black')\n",
    "        ax.plot(x, total_fit, \"r-\", lw=3, label=\"Total Fit\", color = '#4B4DED')\n",
    "        ax.plot(x, g1, \"--\",lw=3, label=\"$L_3$ Peak\", color='#5CECC4')\n",
    "        ax.plot(x, g2, \"--\",lw=3, label=\"$L_2$ Peak\", color='#369178')\n",
    "        ax.plot(x, ar1+ar2, \":\",lw=3, label=\"Continuum states\", color = '#FF6F61')\n",
    "\n",
    "        ax.set_xlabel(\"Energy loss (eV)\")\n",
    "        ax.set_ylabel(\"Intensity (a.u.)\")\n",
    "        ax.legend()\n",
    "        ax.set_yticks([0,])\n",
    "\n",
    "        ax.set_xlim([x.min(), x.max()])\n",
    "        fig.savefig('fig4_.svg', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19216cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "version, number = (2,4)\n",
    "\n",
    "for xx in range(0,4):\n",
    "    fname_pred = fr'fitruns\\run_520-570-670v{xx}.npz'\n",
    "    PC = PredictionChecker(fname_pred) \n",
    "\n",
    "#     spectrum = PC.edge_mean[2,:]   # pick one spatial point\n",
    "    C1, C2, A1, A2, sigma1, sigma2, mu1, mu2 = PC.white_line_calculation_MC(577, 586, fit_window = 5)\n",
    "\n",
    "    np.savez(fr'fitdata\\white_line_results-{xx}.npz', \n",
    "            C1=C1, C2=C2, A1=A1, A2=A2,\n",
    "            sigma1=sigma1, sigma2=sigma2, mu1=mu1, mu2=mu2, spatial_size = PC.spatial_size)\n",
    "\n",
    "    \n",
    "    del C1, C2, A1, A2, sigma1, sigma2, mu1, mu2, PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = np.load(fr'fitdata\\white_line_results-{0}.npz')\n",
    "C1= data['C1']\n",
    "C2= data['C2']\n",
    "sigma1= data['sigma1']\n",
    "sigma2= data['sigma2']\n",
    "A1= data['A1']\n",
    "A2= data['A2']\n",
    "SS = data['spatial_size']\n",
    "print(C1.shape)\n",
    "wl = (A1*sigma1+A2*sigma2)/(C1+C2)\n",
    "# print(wl.shape)\n",
    "wl = wl.reshape(5,*SS)\n",
    "wl.shape\n",
    "\n",
    "plt.imshow(wl.mean(axis=0))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(wl.std(axis=0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
