{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec61d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CLfitter import *\n",
    "from Validation import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902d399-fccb-4b6f-81f9-ad15775c5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EELSBackgroundNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear( 2, 16),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7600a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- Synthetic data generation -----------\n",
    "SNR = 10\n",
    "pre_edge_region = 30\n",
    "\n",
    "E_start, E_stop = 300,600\n",
    "E_edge = E_start+pre_edge_region\n",
    "\n",
    "SIG = SpectralImageGenerator(20, 20, 900, E_start, E_stop)\n",
    "syntheticdata, energy_axis = SIG.generate_realistic_spectral_image(gaussian_snr = SNR, A_range=(1e5,1e6),r_range=(2,3),\n",
    "                                                                    scale= 50)\n",
    "syntheticdata = syntheticdata.reshape(900, 400)\n",
    "\n",
    "ground_truth = SIG.background.reshape(900,400)\n",
    "\n",
    "\n",
    "#----------- Data loading -----------\n",
    "handler = DataHandler()\n",
    "handler.other_data(syntheticdata, np.arange(20), np.arange(20), energy_axis)\n",
    "signal =  handler.signal.copy()\n",
    "i = (E_start-5 ,E_edge ,E_stop+5)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "#----------- pre-processing -----------\n",
    "range_mask = (handler.energy_axis > i[0]) & (handler.energy_axis < i[-1])  # Range for clustering shape [n_E_1]\n",
    "\n",
    "energy_range = handler.energy_axis[range_mask] # shape [n_E_1]\n",
    "signal_range = signal.copy()[range_mask,:]  # shape [n_E_1, n_y*n_x]\n",
    "ground_truth_range = ground_truth.copy()[range_mask,:]\n",
    "pre_edge_mask = (energy_range > i[0]) & (energy_range < i[1])  # Range for pre-edge shape [n_E_2]\n",
    "\n",
    "\n",
    "#----------- clustering  -----------\n",
    "clusterer = ClusterAnalyzer(signal_range)\n",
    "clusterer.cluster_data(n_clusters = 6, pre_edge_mask=pre_edge_mask,)\n",
    "clusterer.cholesky_decomp()\n",
    "\n",
    "X_builder = X_Builder(energy_range)\n",
    "X_builder.prepare_X_mc_data(clusterer.cluster_centers, i[1])\n",
    "X_builder.prepare_X_eval_data(clusterer.total_integrated_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea0876-c440-47a7-82b8-09ce80011d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_background(ii, signal_range, pre_edge_mask, X_builder, clusterer, i):\n",
    "    background_trainer = BackgroundTrainer(\n",
    "        signal=signal_range,\n",
    "        pre_edge_mask=pre_edge_mask,\n",
    "        X_mc=X_builder.X_mc,\n",
    "        X_eval=X_builder.X_eval,\n",
    "        clustered_spectra_mean=clusterer.clusters_mean,\n",
    "        triangular_matices=clusterer.triangular_matices,\n",
    "        covariance_matrices=clusterer.clusters_covariance,\n",
    "        cluster_labels=clusterer.clusters\n",
    "    )\n",
    "\n",
    "    background_trainer.train_MC_replica_consecutive(\n",
    "        n_mc_replicas=10, \n",
    "        epochs=20000, \n",
    "        edge_onset=i[1],\n",
    "        replica_version='covariance',\n",
    "        model = EELSBackgroundNN(),        \n",
    "        progress = False,\n",
    "        logging = False\n",
    "    )\n",
    "\n",
    "    np.savez(fr'validationresults/pred_{ii}.npz', pred = background_trainer.background)\n",
    "\n",
    "\n",
    "\n",
    "# Number of parallel jobs (adjust based on your CPU cores)\n",
    "n_jobs = 80  # e.g., 4 cores\n",
    "\n",
    "Parallel(n_jobs=n_jobs)(\n",
    "    delayed(train_background)(ii, signal_range, pre_edge_mask, X_builder, clusterer, i)\n",
    "    for ii in range(0, 1)\n",
    ")\n",
    "\n",
    "np.savez('validationresults/mc_data.npz', cov = clusterer.clusters_covariance, mean = clusterer.clusters_mean, labels = clusterer.clusters)\n",
    "np.savez('validationresults/run_data.npz', signal = signal, GT = ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2129a1d-792c-484a-a242-2b2917406b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preds = []\n",
    "for ii in range(1):\n",
    "    preds.append(np.load(fr'validationresults/pred_{ii}.npz')['pred'])  \n",
    "\n",
    "GT = np.load(r'validationresults/run_data.npz')['GT']\n",
    "signal = np.load(r'validationresults/run_data.npz')['signal']\n",
    "\n",
    "predictions = np.concatenate(preds, axis=0)\n",
    "\n",
    "pred_std = np.std(predictions, axis=0).T\n",
    "pred_mean = np.mean(predictions, axis=0).T\n",
    "\n",
    "predictions = np.concatenate(preds, axis=0)\n",
    "pred_median = np.median(predictions, axis=0)\n",
    "upper, lower = np.percentile(predictions, [16,84], axis=0)\n",
    "pred_error = (lower-pred_median)\n",
    "\n",
    "normalized_difference_to_theory = (predictions - GT.T) / pred_error\n",
    "normalized_difference_to_theory[np.abs(normalized_difference_to_theory)>100] = None # get rid of extreme outliers skewing data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))  # square figure\n",
    "\n",
    "# Histogram\n",
    "ax.hist(normalized_difference_to_theory.flatten(), bins=100, density=True, \n",
    "        alpha=0.6, color='#5CECC4', edgecolor='#d45087', linewidth=0.5, label='Replica Distribution')\n",
    "\n",
    "# Theoretical Normal distribution\n",
    "x = np.linspace(-10, 10, 10000)\n",
    "ax.plot(x, 1/np.sqrt(2*np.pi)*np.exp(-x**2/2), c='#003f5c', lw=2, label='Normal Distribution')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('Difference to Theory ($\\\\sigma$)', fontsize=20)\n",
    "ax.set_ylabel('Probability Density', fontsize=20)\n",
    "\n",
    "# Limit\n",
    "ax.set_xlim(-5,5)\n",
    "\n",
    "ax.set_yticks([0])\n",
    "ax.set_xticks([-4,-2,0,2,4])\n",
    "\n",
    "ax.legend(fontsize=20)\n",
    "\n",
    "# Tight layout\n",
    "fig.tight_layout()\n",
    "plt.savefig('fig3_histogram.svg', bbox_inches='tight')\n",
    "plt.savefig('fig3_histogram.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bad84-247e-4569-b3a2-f499db8146ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'Code')))\n",
    "\n",
    "from CLfitter import *\n",
    "\n",
    "cluster_data = np.load(r'validationresults/mc_data.npz')\n",
    "run_data = np.load(r'validationresults/run_data.npz')\n",
    "signal = run_data['signal']\n",
    "labels = cluster_data['labels']\n",
    "cov = cluster_data['cov']\n",
    "mean = cluster_data['mean']\n",
    "\n",
    "clusterer = ClusterAnalyzer(signal)\n",
    "clusterer.cluster_data(n_clusters = mean.shape[1]+1)\n",
    "centers = clusterer.cluster_centers\n",
    "TII = np.log(signal.sum(axis=0))\n",
    "TII_max = (TII >= centers.max())\n",
    "TII_min = (TII <= centers.min())\n",
    "TII_middle =  (TII <= centers.max())&(TII >= centers.min())\n",
    "\n",
    "# preds = []\n",
    "# for ii in range(1,19):\n",
    "#     preds.append(np.load(fr'validationresults/pred_{ii}.npz')['pred'])  \n",
    "predictions = np.concatenate(preds, axis=0)\n",
    "pred_median = np.median(predictions, axis=0)\n",
    "lower, upper = np.percentile(predictions, [16,84], axis=0)\n",
    "pred_error = (upper-lower)[:,:len(cov)]/2\n",
    "print(pred_error.shape, cov.shape)\n",
    "# pred_error = predictions.std(axis=0)\n",
    "cluster_std = np.zeros_like(pred_error)\n",
    "for i in range(np.max(labels)+1):\n",
    "    mu = mean[:,i]       # shape (E,)\n",
    "    sigma2 = np.diag(cov[:,:,i])     # diag of covariance, shape (E,)\n",
    "    \n",
    "    sigma_linear = np.sqrt( (np.exp(sigma2) - 1) * np.exp(2*mu + sigma2) )\n",
    "    cluster_std[labels == i] = sigma_linear#np.sqrt(np.exp(np.diag(cov[:,:,i])))\n",
    "\n",
    "\n",
    "TII_expanded = np.repeat(TII[:, None], cluster_std.shape[1], axis=1).flatten()\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "# ---- figure and square axes ----\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_axes([0.2,0.2,0.7,0.7])\n",
    "# ---- scatter plot ----\n",
    "\n",
    "\n",
    "sc = ax.scatter(\n",
    "    cluster_std[TII_max].flatten()/cluster_std.min(),\n",
    "    pred_error[TII_max].flatten()/cluster_std.min(),\n",
    "    c='#bc5090',\n",
    "    s=6,\n",
    "    edgecolors='none',\n",
    "    label = 'Upper-Extrapolated Values'\n",
    ")\n",
    "\n",
    "sc = ax.scatter(\n",
    "    cluster_std[TII_middle].flatten()/cluster_std.min(),\n",
    "    pred_error[TII_middle].flatten()/cluster_std.min(),\n",
    "    c='#003f5c',\n",
    "    s=6,\n",
    "    edgecolors='none',\n",
    "    label = 'Interpolated Values'\n",
    "    \n",
    ")\n",
    "\n",
    "sc = ax.scatter(\n",
    "    cluster_std[TII_min].flatten()/cluster_std.min(),\n",
    "    pred_error[TII_min].flatten()/cluster_std.min(),\n",
    "    c=\"#7d72c6\",\n",
    "    s=6,\n",
    "    edgecolors='none',\n",
    "    label = 'Lower-Extrapolated Values'    \n",
    ")\n",
    "\n",
    "\n",
    "# 1:1 line\n",
    "xmin, xmax = ax.get_xlim()\n",
    "x_line = np.linspace(0, 5, 100)\n",
    "ax.plot(x_line, x_line, linestyle='--', color='#ff6361', lw = 3)\n",
    "\n",
    "ax.set_xlim(0, 5)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "plt.tight_layout()\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "\n",
    "# lgnd = plt.legend(markerscale=4)\n",
    "\n",
    "# for handle in lgnd.legend_handles:\n",
    "#     handle.set_sizes([30.0])\n",
    "plt.savefig('scatterplotcolored_inside.svg')\n",
    "plt.savefig('scatterplotcolored_inside.png', dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "# ---- figure and square axes ----\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_axes([0.2,0.2,0.7,0.7])\n",
    "# ---- scatter plot ----\n",
    "\n",
    "\n",
    "sc = ax.scatter(\n",
    "    cluster_std[TII_max].flatten()[1]/cluster_std.min(),\n",
    "    pred_error[TII_max].flatten()[1]/cluster_std.min(),\n",
    "    c='#bc5090',\n",
    "    s=6,\n",
    "    edgecolors='none',\n",
    "    label = 'Upper-Extrapolated Values'\n",
    ")\n",
    "\n",
    "sc = ax.scatter(\n",
    "    cluster_std[TII_middle].flatten()[1]/cluster_std.min(),\n",
    "    pred_error[TII_middle].flatten()[1]/cluster_std.min(),\n",
    "    c='#003f5c',\n",
    "    s=6,\n",
    "    edgecolors='none',\n",
    "    label = 'Interpolated Values'\n",
    "    \n",
    ")\n",
    "\n",
    "sc = ax.scatter(\n",
    "    cluster_std[TII_min].flatten()[1]/cluster_std.min(),\n",
    "    pred_error[TII_min].flatten()[1]/cluster_std.min(),\n",
    "    c='#7d72c6',\n",
    "    s=6,\n",
    "    edgecolors='none',\n",
    "    label = 'Lower-Extrapolated Values'    \n",
    ")\n",
    "\n",
    "# --- axes & formatting ---\n",
    "ax.set_ylabel('NN uncertainty (a.u.)', fontsize=20)\n",
    "ax.set_xlabel('MC replica uncertainty (a.u.)', fontsize=20)\n",
    "\n",
    "# 1:1 line\n",
    "xmin, xmax = ax.get_xlim()\n",
    "x_line = np.linspace(0, 5, 100)\n",
    "ax.plot(x_line, x_line, linestyle='--', color='#FF6F61', lw = 3)\n",
    "\n",
    "ax.set_xlim(0, 5)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "plt.tight_layout()\n",
    "lgnd = plt.legend(markerscale=4)\n",
    "\n",
    "# for handle in lgnd.legend_handles:\n",
    "#     handle.set_sizes([30.0])\n",
    "plt.savefig('scatterplotcolored_outside.svg')\n",
    "plt.savefig('scatterplotcolored.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_trainer = BackgroundTrainer(\n",
    "    signal=signal_range,\n",
    "    pre_edge_mask=pre_edge_mask,\n",
    "    X_mc=X_builder.X_mc,\n",
    "    X_eval=X_builder.X_eval,\n",
    "    clustered_spectra_mean=clusterer.clusters_mean,\n",
    "    triangular_matices=None,\n",
    "    covariance_matrices=clusterer.clusters_covariance,\n",
    "    cluster_labels=clusterer.clusters\n",
    "\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    cluster_ids = clusterer.clusters == i\n",
    "        # Original cluster mean (log-space)\n",
    "    cluster_mean = clusterer.clusters_mean[:, i]\n",
    "\n",
    "    # Draw replicas\n",
    "    replicas = background_trainer._generate_mc_replica_covariance()[:, i][None,:]\n",
    "    for ii in range(2):\n",
    "        replica = background_trainer._generate_mc_replica_covariance()[:, i][None,:]\n",
    "        replicas = np.concatenate((replicas, replica), axis=0 )\n",
    "    # replicas = [background_trainer._generate_mc_replica_covariance()[:, i] for _ in range(1000)]\n",
    "    # replicas = np.stack(replicas, axis=0)  # shape (n_samples, n_E)\n",
    "    print(replicas.shape)\n",
    "    replica_size = np.mean(replicas, axis=0).shape[0]\n",
    "    print(replica_size)\n",
    "    plt.figure(figsize=(8, 8), dpi=300)\n",
    "    plt.plot(energy_range[:replica_size], np.mean(replicas, axis=0), label=\"Replica mean\", color=\"#5CECC4\", linewidth=4)\n",
    "    plt.fill_between(\n",
    "        energy_range[:replica_size],\n",
    "        np.percentile(replicas, 5, axis=0),\n",
    "        np.percentile(replicas, 95, axis=0),\n",
    "        color='#5CECC4',\n",
    "        alpha=0.5, label=\"Replica uncertainty (90% CL)\",\n",
    "        hatch = 'xx'\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.plot(energy_range[:replica_size], np.mean(np.log(signal_range[:replica_size][:,cluster_ids]), axis = 1), label=f\"Cluster mean\", color=\"#FF6F61\")\n",
    "    plt.fill_between(\n",
    "        energy_range[:replica_size],\n",
    "        np.log(np.percentile(signal_range[:replica_size][:,cluster_ids], 5, axis=1)),\n",
    "        np.log(np.percentile(signal_range[:replica_size][:,cluster_ids], 95, axis=1)),\n",
    "        alpha=0.3, color='#FF6F61',\n",
    "        label=f\"Cluster Uncertainty (90% CL)\",\n",
    "        hatch = '..'\n",
    "    )\n",
    "    plt.xlabel(\"Energy Loss [eV]\",fontsize = 20)\n",
    "    plt.ylabel(\"Log Intensity [a.u.]\",fontsize = 20)\n",
    "    plt.yticks([])\n",
    "    plt.xlim(energy_range[0], energy_range[90])\n",
    "    plt.legend(fontsize = 18)\n",
    "    plt.savefig(r'ch2_XX_validationreplicas.pdf', bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
